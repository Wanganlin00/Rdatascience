24/08/25 13:08:33.713 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/E:/spark/spark-3.3.4-bin-hadoop3/conf/hive-site.xml
24/08/25 13:08:34.471 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.4
24/08/25 13:08:34.548 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/08/25 13:08:34.856 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/08/25 13:08:34.966 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/08/25 13:08:34.968 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/08/25 13:08:34.970 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/08/25 13:08:34.972 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/08/25 13:08:35.076 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/08/25 13:08:35.122 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/08/25 13:08:35.125 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/08/25 13:08:35.497 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: DELL
24/08/25 13:08:35.498 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: DELL
24/08/25 13:08:35.500 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/08/25 13:08:35.503 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/08/25 13:08:35.504 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(DELL); groups with view permissions: Set(); users  with modify permissions: Set(DELL); groups with modify permissions: Set()
24/08/25 13:08:35.954 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 64089.
24/08/25 13:08:36.072 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/08/25 13:08:36.244 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/08/25 13:08:36.367 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/08/25 13:08:36.370 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/08/25 13:08:36.384 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/08/25 13:08:36.503 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\blockmgr-d5ad6a71-1673-480f-ad75-12512db0ebfd
24/08/25 13:08:36.587 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/08/25 13:08:36.663 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/08/25 13:08:36.674 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [E:/spark/spark-3.3.4-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/08/25 13:08:37.601 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/08/25 13:08:37.768 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/D:/R-4.4.1/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://licenses.graphpad.com:64089/jars/sparklyr-3.0-2.12.jar with timestamp 1724562514446
24/08/25 13:08:38.060 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host licenses.graphpad.com
24/08/25 13:08:38.094 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/08/25 13:08:38.140 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://licenses.graphpad.com:64089/jars/sparklyr-3.0-2.12.jar with timestamp 1724562514446
24/08/25 13:08:38.297 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to licenses.graphpad.com/127.0.0.1:64089 after 82 ms (0 ms spent in bootstraps)
24/08/25 13:08:38.313 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://licenses.graphpad.com:64089/jars/sparklyr-3.0-2.12.jar to E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387\userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7\fetchFileTemp896043815909354960.tmp
24/08/25 13:08:38.598 nioEventLoopGroup-2-2 INFO Executor: Adding file:/E:/spark/spark-3.3.4-bin-hadoop3/tmp/local/spark-0f0d4f7f-1897-4deb-8740-de4558b43387/userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7/sparklyr-3.0-2.12.jar to class loader
24/08/25 13:08:38.655 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64140.
24/08/25 13:08:38.657 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on licenses.graphpad.com:64140
24/08/25 13:08:38.663 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/08/25 13:08:38.698 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, licenses.graphpad.com, 64140, None)
24/08/25 13:08:38.712 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager licenses.graphpad.com:64140 with 912.3 MiB RAM, BlockManagerId(driver, licenses.graphpad.com, 64140, None)
24/08/25 13:08:38.725 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, licenses.graphpad.com, 64140, None)
24/08/25 13:08:38.729 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, licenses.graphpad.com, 64140, None)
24/08/25 13:08:40.082 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('E:/spark/spark-3.3.4-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/08/25 13:08:40.128 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/E:/spark/spark-3.3.4-bin-hadoop3/tmp/hive'.
24/08/25 13:08:55.306 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/08/25 13:08:56.017 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/E:/spark/spark-3.3.4-bin-hadoop3/conf/hive-site.xml
24/08/25 13:08:56.790 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/E:/spark/spark-3.3.4-bin-hadoop3/tmp/hive
24/08/25 13:08:57.750 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/08/25 13:08:57.752 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/08/25 13:08:57.753 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/08/25 13:08:57.893 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/08/25 13:08:58.458 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/08/25 13:08:58.462 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/08/25 13:09:02.577 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/08/25 13:09:07.702 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/08/25 13:09:07.709 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/08/25 13:09:07.948 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/08/25 13:09:07.948 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.43.97
24/08/25 13:09:08.039 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/08/25 13:09:08.585 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/08/25 13:09:08.592 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/08/25 13:09:08.756 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/08/25 13:09:09.590 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:09:09.597 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:09:09.663 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/08/25 13:09:09.664 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/08/25 13:09:09.666 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/08/25 13:09:09.669 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:09:09.671 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:09:09.677 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:09:09.678 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:09:09.683 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:09:09.684 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:09:11.078 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:09:11.079 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:09:11.084 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:09:11.085 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:09:11.089 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:09:11.090 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:09:53.316 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:09:53.317 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:09:53.324 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:09:53.325 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:09:53.331 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:09:53.332 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:09:55.478 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 638.2835 ms
24/08/25 13:09:55.952 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:09:55.981 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.022078 s
24/08/25 13:10:01.224 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 44.5583 ms
24/08/25 13:10:01.284 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:01.338 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:10:01.340 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/08/25 13:10:01.342 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:01.345 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:01.356 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:01.593 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
24/08/25 13:10:02.655 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
24/08/25 13:10:02.671 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:10:02.688 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:02.745 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:02.752 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/08/25 13:10:03.896 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:10:03.956 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/08/25 13:10:05.218 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
24/08/25 13:10:05.243 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1821 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:05.250 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/08/25 13:10:05.272 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 3.865 s
24/08/25 13:10:05.283 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:05.285 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/08/25 13:10:05.287 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 4.001547 s
24/08/25 13:10:05.406 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 49.5585 ms
24/08/25 13:10:07.211 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:07.214 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:10:07.214 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/08/25 13:10:07.214 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:07.215 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:07.217 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:07.227 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
24/08/25 13:10:07.235 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
24/08/25 13:10:07.239 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:10:07.241 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:07.243 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:07.244 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/08/25 13:10:07.246 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:10:07.248 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/08/25 13:10:07.265 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1362 bytes result sent to driver
24/08/25 13:10:07.269 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 23 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:07.270 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/08/25 13:10:07.272 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.052 s
24/08/25 13:10:07.273 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:07.274 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/08/25 13:10:07.275 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.062974 s
24/08/25 13:10:07.934 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:10:07.935 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:10:07.941 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:10:07.941 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:10:07.946 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:10:07.947 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:10:08.227 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 160.7252 ms
24/08/25 13:10:08.352 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.9002 ms
24/08/25 13:10:08.408 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 28.9119 ms
24/08/25 13:10:17.114 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 34.2822 ms
24/08/25 13:10:17.209 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:17.212 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:10:17.213 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/08/25 13:10:17.213 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:17.227 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:17.230 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:17.301 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 16.0 KiB, free 912.3 MiB)
24/08/25 13:10:17.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 912.3 MiB)
24/08/25 13:10:17.330 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on licenses.graphpad.com:64140 (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:10:17.333 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:17.335 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:17.335 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/08/25 13:10:17.343 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:10:17.345 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/08/25 13:10:17.631 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 4.2 KiB, free 912.3 MiB)
24/08/25 13:10:17.636 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_11_0 in memory on licenses.graphpad.com:64140 (size: 4.2 KiB, free: 912.3 MiB)
24/08/25 13:10:17.777 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 106.3048 ms
24/08/25 13:10:17.955 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 141.074 ms
24/08/25 13:10:18.040 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_11_0]
24/08/25 13:10:18.045 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1739 bytes result sent to driver
24/08/25 13:10:18.048 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 710 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:18.051 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.818 s
24/08/25 13:10:18.053 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:18.056 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/08/25 13:10:18.056 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/08/25 13:10:18.058 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.847830 s
24/08/25 13:10:18.104 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 31.9855 ms
24/08/25 13:10:20.083 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:20.086 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:10:20.087 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/08/25 13:10:20.087 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:20.095 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:20.098 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[19] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:20.118 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.0 KiB, free 912.2 MiB)
24/08/25 13:10:20.174 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 912.2 MiB)
24/08/25 13:10:20.176 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on licenses.graphpad.com:64140 (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:10:20.178 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:20.179 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:20.181 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/08/25 13:10:20.197 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:10:20.200 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/08/25 13:10:20.216 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:10:20.233 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2870 bytes result sent to driver
24/08/25 13:10:20.239 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 44 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:20.242 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/08/25 13:10:20.244 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0.143 s
24/08/25 13:10:20.245 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:20.246 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/08/25 13:10:20.247 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.162463 s
24/08/25 13:10:20.287 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on licenses.graphpad.com:64140 in memory (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:10:20.337 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:10:20.359 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:10:32.703 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:32.705 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:10:32.706 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/08/25 13:10:32.706 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:32.707 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:32.711 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:32.735 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.0 KiB, free 912.3 MiB)
24/08/25 13:10:32.743 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 912.3 MiB)
24/08/25 13:10:32.746 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on licenses.graphpad.com:64140 (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:10:32.748 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:32.750 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:32.750 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/08/25 13:10:32.753 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:10:32.755 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/08/25 13:10:32.767 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:10:32.776 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2827 bytes result sent to driver
24/08/25 13:10:32.779 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 27 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:32.779 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/08/25 13:10:32.781 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0.067 s
24/08/25 13:10:32.782 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:32.783 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/08/25 13:10:32.784 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.079229 s
24/08/25 13:10:53.776 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.642 ms
24/08/25 13:10:53.811 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:53.813 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:10:53.814 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/08/25 13:10:53.814 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:53.814 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:53.817 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:53.825 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KiB, free 912.2 MiB)
24/08/25 13:10:53.832 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:10:53.836 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:10:53.837 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:53.839 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:53.839 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/08/25 13:10:53.843 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:10:53.845 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/08/25 13:10:53.862 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1362 bytes result sent to driver
24/08/25 13:10:53.863 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 22 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:53.864 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/08/25 13:10:53.866 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0.045 s
24/08/25 13:10:53.867 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:53.867 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/08/25 13:10:53.868 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0.055567 s
24/08/25 13:10:53.897 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.7379 ms
24/08/25 13:10:54.493 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.646 ms
24/08/25 13:10:54.633 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at samplingutils.scala:37
24/08/25 13:10:54.636 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (aggregate at samplingutils.scala:37) with 1 output partitions
24/08/25 13:10:54.636 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (aggregate at samplingutils.scala:37)
24/08/25 13:10:54.636 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:54.637 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:54.640 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[29] at rdd at <unknown>:0), which has no missing parents
24/08/25 13:10:54.737 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.4 KiB, free 912.2 MiB)
24/08/25 13:10:54.754 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 912.2 MiB)
24/08/25 13:10:54.758 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on licenses.graphpad.com:64140 (size: 8.0 KiB, free: 912.3 MiB)
24/08/25 13:10:54.759 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:54.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[29] at rdd at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:54.762 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/08/25 13:10:54.766 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:10:54.769 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/08/25 13:10:55.004 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 18.3694 ms
24/08/25 13:10:55.023 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 4798 bytes result sent to driver
24/08/25 13:10:55.029 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 264 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:55.030 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/08/25 13:10:55.032 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (aggregate at samplingutils.scala:37) finished in 0.387 s
24/08/25 13:10:55.032 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:55.033 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/08/25 13:10:55.037 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: aggregate at samplingutils.scala:37, took 0.402343 s
24/08/25 13:10:55.388 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:55.389 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:10:55.390 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
24/08/25 13:10:55.390 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:55.391 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:55.393 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[33] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:55.400 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.1 KiB, free 912.2 MiB)
24/08/25 13:10:55.408 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:10:55.412 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:10:55.414 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:55.416 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:10:55.416 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/08/25 13:10:55.421 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.424 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/08/25 13:10:55.435 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1362 bytes result sent to driver
24/08/25 13:10:55.437 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 17 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:10:55.438 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/08/25 13:10:55.439 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0.043 s
24/08/25 13:10:55.440 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:55.441 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/08/25 13:10:55.442 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0.054033 s
24/08/25 13:10:55.694 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.7527 ms
24/08/25 13:10:55.773 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:10:55.775 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (collect at utils.scala:26) with 8 output partitions
24/08/25 13:10:55.775 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:26)
24/08/25 13:10:55.776 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:10:55.776 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:10:55.778 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at collect at utils.scala:26), which has no missing parents
24/08/25 13:10:55.787 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 19.0 KiB, free 912.2 MiB)
24/08/25 13:10:55.794 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 912.2 MiB)
24/08/25 13:10:55.797 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on licenses.graphpad.com:64140 (size: 8.8 KiB, free: 912.3 MiB)
24/08/25 13:10:55.797 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1509
24/08/25 13:10:55.798 dag-scheduler-event-loop INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
24/08/25 13:10:55.799 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 8 tasks resource profile 0
24/08/25 13:10:55.804 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.806 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 9) (licenses.graphpad.com, executor driver, partition 1, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.807 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 10) (licenses.graphpad.com, executor driver, partition 2, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.808 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 11) (licenses.graphpad.com, executor driver, partition 3, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.809 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 12) (licenses.graphpad.com, executor driver, partition 4, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.810 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 13) (licenses.graphpad.com, executor driver, partition 5, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.812 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 14) (licenses.graphpad.com, executor driver, partition 6, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.815 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 15) (licenses.graphpad.com, executor driver, partition 7, PROCESS_LOCAL, 5673 bytes) taskResourceAssignments Map()
24/08/25 13:10:55.816 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/08/25 13:10:55.819 Executor task launch worker for task 1.0 in stage 8.0 (TID 9) INFO Executor: Running task 1.0 in stage 8.0 (TID 9)
24/08/25 13:10:55.821 Executor task launch worker for task 2.0 in stage 8.0 (TID 10) INFO Executor: Running task 2.0 in stage 8.0 (TID 10)
24/08/25 13:10:55.822 Executor task launch worker for task 3.0 in stage 8.0 (TID 11) INFO Executor: Running task 3.0 in stage 8.0 (TID 11)
24/08/25 13:10:55.827 Executor task launch worker for task 4.0 in stage 8.0 (TID 12) INFO Executor: Running task 4.0 in stage 8.0 (TID 12)
24/08/25 13:10:55.829 Executor task launch worker for task 5.0 in stage 8.0 (TID 13) INFO Executor: Running task 5.0 in stage 8.0 (TID 13)
24/08/25 13:10:55.829 Executor task launch worker for task 7.0 in stage 8.0 (TID 15) INFO Executor: Running task 7.0 in stage 8.0 (TID 15)
24/08/25 13:10:55.830 Executor task launch worker for task 6.0 in stage 8.0 (TID 14) INFO Executor: Running task 6.0 in stage 8.0 (TID 14)
24/08/25 13:10:56.096 Executor task launch worker for task 5.0 in stage 8.0 (TID 13) INFO CodeGenerator: Code generated in 87.9577 ms
24/08/25 13:10:56.128 Executor task launch worker for task 4.0 in stage 8.0 (TID 12) INFO Executor: Finished task 4.0 in stage 8.0 (TID 12). 1444 bytes result sent to driver
24/08/25 13:10:56.130 Executor task launch worker for task 2.0 in stage 8.0 (TID 10) INFO Executor: Finished task 2.0 in stage 8.0 (TID 10). 1444 bytes result sent to driver
24/08/25 13:10:56.130 Executor task launch worker for task 3.0 in stage 8.0 (TID 11) INFO Executor: Finished task 3.0 in stage 8.0 (TID 11). 1404 bytes result sent to driver
24/08/25 13:10:56.131 Executor task launch worker for task 6.0 in stage 8.0 (TID 14) INFO Executor: Finished task 6.0 in stage 8.0 (TID 14). 1451 bytes result sent to driver
24/08/25 13:10:56.133 Executor task launch worker for task 7.0 in stage 8.0 (TID 15) INFO Executor: Finished task 7.0 in stage 8.0 (TID 15). 1448 bytes result sent to driver
24/08/25 13:10:56.133 Executor task launch worker for task 1.0 in stage 8.0 (TID 9) INFO Executor: Finished task 1.0 in stage 8.0 (TID 9). 1449 bytes result sent to driver
24/08/25 13:10:56.136 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1409 bytes result sent to driver
24/08/25 13:10:56.136 Executor task launch worker for task 5.0 in stage 8.0 (TID 13) INFO Executor: Finished task 5.0 in stage 8.0 (TID 13). 1456 bytes result sent to driver
24/08/25 13:10:56.142 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 10) in 336 ms on licenses.graphpad.com (executor driver) (1/8)
24/08/25 13:10:56.143 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 12) in 335 ms on licenses.graphpad.com (executor driver) (2/8)
24/08/25 13:10:56.143 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 11) in 336 ms on licenses.graphpad.com (executor driver) (3/8)
24/08/25 13:10:56.147 task-result-getter-3 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 14) in 336 ms on licenses.graphpad.com (executor driver) (4/8)
24/08/25 13:10:56.148 task-result-getter-1 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 15) in 336 ms on licenses.graphpad.com (executor driver) (5/8)
24/08/25 13:10:56.152 task-result-getter-0 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 13) in 342 ms on licenses.graphpad.com (executor driver) (6/8)
24/08/25 13:10:56.156 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 9) in 351 ms on licenses.graphpad.com (executor driver) (7/8)
24/08/25 13:10:56.156 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 354 ms on licenses.graphpad.com (executor driver) (8/8)
24/08/25 13:10:56.157 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/08/25 13:10:56.158 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (collect at utils.scala:26) finished in 0.376 s
24/08/25 13:10:56.160 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:10:56.160 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/08/25 13:10:56.161 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: collect at utils.scala:26, took 0.386279 s
24/08/25 13:11:04.009 nioEventLoopGroup-2-2 INFO Instrumentation: [5732593c] training finished
24/08/25 13:11:04.714 nioEventLoopGroup-2-2 INFO Instrumentation: [10a4f045] training finished
24/08/25 13:11:04.799 nioEventLoopGroup-2-2 INFO Instrumentation: [fcc925bd] Stage class: LinearRegression
24/08/25 13:11:04.801 nioEventLoopGroup-2-2 INFO Instrumentation: [fcc925bd] Stage uid: linear_regression__60de7ffd_b113_4e3a_8393_e0096b8702e9
24/08/25 13:11:05.231 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on licenses.graphpad.com:64140 in memory (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:11:05.245 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on licenses.graphpad.com:64140 in memory (size: 8.0 KiB, free: 912.3 MiB)
24/08/25 13:11:05.258 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on licenses.graphpad.com:64140 in memory (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:11:05.273 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on licenses.graphpad.com:64140 in memory (size: 8.8 KiB, free: 912.3 MiB)
24/08/25 13:11:05.285 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:11:05.299 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:11:05.316 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 89.2725 ms
24/08/25 13:11:05.467 nioEventLoopGroup-2-2 INFO Instrumentation: [fcc925bd] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/08/25 13:11:05.547 nioEventLoopGroup-2-2 INFO Instrumentation: [fcc925bd] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
24/08/25 13:11:05.562 nioEventLoopGroup-2-2 INFO Instrumentation: [fcc925bd] {"numFeatures":1}
24/08/25 13:11:05.732 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 52.7382 ms
24/08/25 13:11:05.782 nioEventLoopGroup-2-2 WARN Instrumentation: [fcc925bd] regParam is zero, which might cause numerical instability and overfitting.
24/08/25 13:11:05.843 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:107
24/08/25 13:11:05.846 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (treeAggregate at WeightedLeastSquares.scala:107) with 1 output partitions
24/08/25 13:11:05.847 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (treeAggregate at WeightedLeastSquares.scala:107)
24/08/25 13:11:05.847 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:05.848 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:05.852 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[51] at treeAggregate at WeightedLeastSquares.scala:107), which has no missing parents
24/08/25 13:11:05.895 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 47.6 KiB, free 912.2 MiB)
24/08/25 13:11:05.901 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 912.2 MiB)
24/08/25 13:11:05.905 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on licenses.graphpad.com:64140 (size: 19.3 KiB, free: 912.3 MiB)
24/08/25 13:11:05.906 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:05.907 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[51] at treeAggregate at WeightedLeastSquares.scala:107) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:05.908 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/08/25 13:11:05.911 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 16) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:11:05.914 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) INFO Executor: Running task 0.0 in stage 9.0 (TID 16)
24/08/25 13:11:06.032 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:11:06.087 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) INFO CodeGenerator: Code generated in 30.744 ms
24/08/25 13:11:06.222 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) INFO CodeGenerator: Code generated in 67.677 ms
24/08/25 13:11:06.327 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS
24/08/25 13:11:06.338 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS
24/08/25 13:11:06.370 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) INFO Executor: Finished task 0.0 in stage 9.0 (TID 16). 1883 bytes result sent to driver
24/08/25 13:11:06.373 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 16) in 463 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:06.374 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/08/25 13:11:06.376 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (treeAggregate at WeightedLeastSquares.scala:107) finished in 0.521 s
24/08/25 13:11:06.376 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:06.377 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/08/25 13:11:06.378 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: treeAggregate at WeightedLeastSquares.scala:107, took 0.533460 s
24/08/25 13:11:06.382 nioEventLoopGroup-2-2 INFO Instrumentation: [fcc925bd] Number of instances: 32.
24/08/25 13:11:06.692 nioEventLoopGroup-2-2 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK
24/08/25 13:11:07.281 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 44.4724 ms
24/08/25 13:11:07.501 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: treeAggregate at Statistics.scala:58
24/08/25 13:11:07.505 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (treeAggregate at Statistics.scala:58) with 1 output partitions
24/08/25 13:11:07.506 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at Statistics.scala:58)
24/08/25 13:11:07.506 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:07.508 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:07.512 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[61] at treeAggregate at Statistics.scala:58), which has no missing parents
24/08/25 13:11:07.543 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 54.0 KiB, free 912.2 MiB)
24/08/25 13:11:07.551 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 22.8 KiB, free 912.2 MiB)
24/08/25 13:11:07.556 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on licenses.graphpad.com:64140 (size: 22.8 KiB, free: 912.3 MiB)
24/08/25 13:11:07.558 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:07.559 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[61] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:07.560 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/08/25 13:11:07.563 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 17) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:11:07.565 Executor task launch worker for task 0.0 in stage 10.0 (TID 17) INFO Executor: Running task 0.0 in stage 10.0 (TID 17)
24/08/25 13:11:09.243 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on licenses.graphpad.com:64140 in memory (size: 19.3 KiB, free: 912.3 MiB)
24/08/25 13:11:09.265 Executor task launch worker for task 0.0 in stage 10.0 (TID 17) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:11:09.307 Executor task launch worker for task 0.0 in stage 10.0 (TID 17) INFO CodeGenerator: Code generated in 26.6537 ms
24/08/25 13:11:09.389 Executor task launch worker for task 0.0 in stage 10.0 (TID 17) INFO Executor: Finished task 0.0 in stage 10.0 (TID 17). 2771 bytes result sent to driver
24/08/25 13:11:09.392 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 17) in 1829 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:09.392 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/08/25 13:11:09.394 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (treeAggregate at Statistics.scala:58) finished in 1.880 s
24/08/25 13:11:09.395 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:09.395 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
24/08/25 13:11:09.396 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: treeAggregate at Statistics.scala:58, took 1.893946 s
24/08/25 13:11:09.407 nioEventLoopGroup-2-2 INFO Instrumentation: [9a9e74a7] training finished
24/08/25 13:11:10.925 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.5616 ms
24/08/25 13:11:10.945 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:10.946 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:10.947 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:26)
24/08/25 13:11:10.947 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:10.947 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:10.950 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[63] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:10.957 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.6 KiB, free 912.2 MiB)
24/08/25 13:11:10.962 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:11:10.965 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:11:10.967 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:10.969 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[63] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:10.969 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/08/25 13:11:10.972 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 18) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:11:10.973 Executor task launch worker for task 0.0 in stage 11.0 (TID 18) INFO Executor: Running task 0.0 in stage 11.0 (TID 18)
24/08/25 13:11:10.984 Executor task launch worker for task 0.0 in stage 11.0 (TID 18) INFO Executor: Finished task 0.0 in stage 11.0 (TID 18). 1319 bytes result sent to driver
24/08/25 13:11:10.987 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 18) in 15 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:10.987 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/08/25 13:11:10.988 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collect at utils.scala:26) finished in 0.035 s
24/08/25 13:11:10.989 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:10.990 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
24/08/25 13:11:10.991 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0.044986 s
24/08/25 13:11:11.019 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.5565 ms
24/08/25 13:11:11.976 nioEventLoopGroup-2-2 INFO Instrumentation: [62ea1d7d] training finished
24/08/25 13:11:12.352 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 18.4969 ms
24/08/25 13:11:12.374 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:12.376 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:12.377 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
24/08/25 13:11:12.377 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:12.377 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:12.381 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[65] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:12.387 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.6 KiB, free 912.2 MiB)
24/08/25 13:11:12.393 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:11:12.398 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:11:12.399 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:12.400 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[65] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:12.400 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/08/25 13:11:12.404 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 19) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:11:12.406 Executor task launch worker for task 0.0 in stage 12.0 (TID 19) INFO Executor: Running task 0.0 in stage 12.0 (TID 19)
24/08/25 13:11:12.416 Executor task launch worker for task 0.0 in stage 12.0 (TID 19) INFO Executor: Finished task 0.0 in stage 12.0 (TID 19). 1362 bytes result sent to driver
24/08/25 13:11:12.421 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 19) in 17 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:12.421 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/08/25 13:11:12.422 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0.039 s
24/08/25 13:11:12.423 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:12.423 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
24/08/25 13:11:12.424 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collect at utils.scala:26, took 0.048507 s
24/08/25 13:11:12.450 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.0649 ms
24/08/25 13:11:14.177 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:14.179 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:14.179 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:26)
24/08/25 13:11:14.179 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:14.180 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:14.181 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[67] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:14.187 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.6 KiB, free 912.2 MiB)
24/08/25 13:11:14.194 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:11:14.197 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:11:14.198 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:14.199 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[67] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:14.199 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/08/25 13:11:14.203 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 20) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:11:14.204 Executor task launch worker for task 0.0 in stage 13.0 (TID 20) INFO Executor: Running task 0.0 in stage 13.0 (TID 20)
24/08/25 13:11:14.212 Executor task launch worker for task 0.0 in stage 13.0 (TID 20) INFO Executor: Finished task 0.0 in stage 13.0 (TID 20). 1362 bytes result sent to driver
24/08/25 13:11:14.214 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 20) in 12 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:14.214 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/08/25 13:11:14.215 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collect at utils.scala:26) finished in 0.032 s
24/08/25 13:11:14.216 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:14.217 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
24/08/25 13:11:14.217 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collect at utils.scala:26, took 0.038782 s
24/08/25 13:11:15.289 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:11:15.290 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:11:15.315 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:11:15.315 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:11:15.321 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:11:15.322 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:11:15.498 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:15.500 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 6 output partitions
24/08/25 13:11:15.500 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
24/08/25 13:11:15.500 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:15.501 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:15.504 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[70] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:15.511 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.1 KiB, free 912.2 MiB)
24/08/25 13:11:15.516 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:11:15.519 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:11:15.521 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:15.522 dag-scheduler-event-loop INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 14 (MapPartitionsRDD[70] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
24/08/25 13:11:15.522 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 6 tasks resource profile 0
24/08/25 13:11:15.525 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 21) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4649 bytes) taskResourceAssignments Map()
24/08/25 13:11:15.525 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 22) (licenses.graphpad.com, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
24/08/25 13:11:15.526 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 23) (licenses.graphpad.com, executor driver, partition 2, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
24/08/25 13:11:15.528 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 24) (licenses.graphpad.com, executor driver, partition 3, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
24/08/25 13:11:15.529 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 25) (licenses.graphpad.com, executor driver, partition 4, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
24/08/25 13:11:15.530 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 26) (licenses.graphpad.com, executor driver, partition 5, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
24/08/25 13:11:15.531 Executor task launch worker for task 1.0 in stage 14.0 (TID 22) INFO Executor: Running task 1.0 in stage 14.0 (TID 22)
24/08/25 13:11:15.531 Executor task launch worker for task 3.0 in stage 14.0 (TID 24) INFO Executor: Running task 3.0 in stage 14.0 (TID 24)
24/08/25 13:11:15.531 Executor task launch worker for task 2.0 in stage 14.0 (TID 23) INFO Executor: Running task 2.0 in stage 14.0 (TID 23)
24/08/25 13:11:15.531 Executor task launch worker for task 0.0 in stage 14.0 (TID 21) INFO Executor: Running task 0.0 in stage 14.0 (TID 21)
24/08/25 13:11:15.532 Executor task launch worker for task 5.0 in stage 14.0 (TID 26) INFO Executor: Running task 5.0 in stage 14.0 (TID 26)
24/08/25 13:11:15.533 Executor task launch worker for task 4.0 in stage 14.0 (TID 25) INFO Executor: Running task 4.0 in stage 14.0 (TID 25)
24/08/25 13:11:15.545 Executor task launch worker for task 0.0 in stage 14.0 (TID 21) INFO Executor: Finished task 0.0 in stage 14.0 (TID 21). 1377 bytes result sent to driver
24/08/25 13:11:15.545 Executor task launch worker for task 2.0 in stage 14.0 (TID 23) INFO Executor: Finished task 2.0 in stage 14.0 (TID 23). 1382 bytes result sent to driver
24/08/25 13:11:15.545 Executor task launch worker for task 3.0 in stage 14.0 (TID 24) INFO Executor: Finished task 3.0 in stage 14.0 (TID 24). 1425 bytes result sent to driver
24/08/25 13:11:15.545 Executor task launch worker for task 5.0 in stage 14.0 (TID 26) INFO Executor: Finished task 5.0 in stage 14.0 (TID 26). 1382 bytes result sent to driver
24/08/25 13:11:15.545 Executor task launch worker for task 1.0 in stage 14.0 (TID 22) INFO Executor: Finished task 1.0 in stage 14.0 (TID 22). 1425 bytes result sent to driver
24/08/25 13:11:15.545 Executor task launch worker for task 4.0 in stage 14.0 (TID 25) INFO Executor: Finished task 4.0 in stage 14.0 (TID 25). 1425 bytes result sent to driver
24/08/25 13:11:15.546 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 24) in 18 ms on licenses.graphpad.com (executor driver) (1/6)
24/08/25 13:11:15.547 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 21) in 23 ms on licenses.graphpad.com (executor driver) (2/6)
24/08/25 13:11:15.547 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 23) in 21 ms on licenses.graphpad.com (executor driver) (3/6)
24/08/25 13:11:15.548 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 22) in 23 ms on licenses.graphpad.com (executor driver) (4/6)
24/08/25 13:11:15.550 task-result-getter-3 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 26) in 20 ms on licenses.graphpad.com (executor driver) (5/6)
24/08/25 13:11:15.553 task-result-getter-0 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 25) in 24 ms on licenses.graphpad.com (executor driver) (6/6)
24/08/25 13:11:15.553 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/08/25 13:11:15.554 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0.048 s
24/08/25 13:11:15.555 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:15.555 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
24/08/25 13:11:15.556 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0.056979 s
24/08/25 13:11:15.574 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.6392 ms
24/08/25 13:11:15.900 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.9063 ms
24/08/25 13:11:15.934 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:15.936 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:15.937 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:26)
24/08/25 13:11:15.937 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:15.937 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:15.941 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[73] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:15.945 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KiB, free 912.2 MiB)
24/08/25 13:11:15.949 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.2 MiB)
24/08/25 13:11:15.951 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on licenses.graphpad.com:64140 (size: 3.6 KiB, free: 912.3 MiB)
24/08/25 13:11:15.952 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:15.954 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[73] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:15.954 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/08/25 13:11:15.957 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 27) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:11:15.958 Executor task launch worker for task 0.0 in stage 15.0 (TID 27) INFO Executor: Running task 0.0 in stage 15.0 (TID 27)
24/08/25 13:11:15.967 Executor task launch worker for task 0.0 in stage 15.0 (TID 27) INFO Executor: Finished task 0.0 in stage 15.0 (TID 27). 1318 bytes result sent to driver
24/08/25 13:11:15.968 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 27) in 12 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:15.969 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/08/25 13:11:15.970 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 15 (collect at utils.scala:26) finished in 0.028 s
24/08/25 13:11:15.971 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:15.972 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
24/08/25 13:11:15.972 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0.036963 s
24/08/25 13:11:15.989 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.9486 ms
24/08/25 13:11:16.390 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:16.392 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:16.392 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:26)
24/08/25 13:11:16.393 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:16.393 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:16.396 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[75] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:16.402 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KiB, free 912.2 MiB)
24/08/25 13:11:16.427 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 912.2 MiB)
24/08/25 13:11:16.429 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on licenses.graphpad.com:64140 (size: 3.6 KiB, free: 912.3 MiB)
24/08/25 13:11:16.430 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:16.432 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[75] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:16.432 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/08/25 13:11:16.437 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 28) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:11:16.440 Executor task launch worker for task 0.0 in stage 16.0 (TID 28) INFO Executor: Running task 0.0 in stage 16.0 (TID 28)
24/08/25 13:11:16.447 Executor task launch worker for task 0.0 in stage 16.0 (TID 28) INFO Executor: Finished task 0.0 in stage 16.0 (TID 28). 1361 bytes result sent to driver
24/08/25 13:11:16.448 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 28) in 12 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:16.449 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/08/25 13:11:16.450 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 16 (collect at utils.scala:26) finished in 0.051 s
24/08/25 13:11:16.451 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:16.451 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
24/08/25 13:11:16.453 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0.061681 s
24/08/25 13:11:16.667 nioEventLoopGroup-2-2 INFO Instrumentation: [8c609181] training finished
24/08/25 13:11:16.704 nioEventLoopGroup-2-2 INFO Instrumentation: [d58f13d1] training finished
24/08/25 13:11:17.050 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 47.3779 ms
24/08/25 13:11:17.119 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:17.122 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:17.122 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:26)
24/08/25 13:11:17.122 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:17.123 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:17.125 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[77] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:17.130 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KiB, free 912.1 MiB)
24/08/25 13:11:17.175 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.1 MiB)
24/08/25 13:11:17.178 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:11:17.179 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:17.180 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[77] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:17.181 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/08/25 13:11:17.182 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 29) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:11:17.186 Executor task launch worker for task 0.0 in stage 17.0 (TID 29) INFO Executor: Running task 0.0 in stage 17.0 (TID 29)
24/08/25 13:11:17.203 Executor task launch worker for task 0.0 in stage 17.0 (TID 29) INFO Executor: Finished task 0.0 in stage 17.0 (TID 29). 1362 bytes result sent to driver
24/08/25 13:11:17.206 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 29) in 24 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:17.206 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/08/25 13:11:17.207 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 17 (collect at utils.scala:26) finished in 0.080 s
24/08/25 13:11:17.208 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:17.208 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
24/08/25 13:11:17.209 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0.088768 s
24/08/25 13:11:17.242 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 27.8393 ms
24/08/25 13:11:19.259 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 38.0159 ms
24/08/25 13:11:19.283 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.2029 ms
24/08/25 13:11:19.431 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 85 (collect at utils.scala:26) as input to shuffle 0
24/08/25 13:11:19.450 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.0686 ms
24/08/25 13:11:19.454 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 19 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:19.456 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 18 (collect at utils.scala:26)
24/08/25 13:11:19.457 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:19.460 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:19.466 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[85] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:19.516 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 43.5 KiB, free 912.1 MiB)
24/08/25 13:11:19.524 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 912.1 MiB)
24/08/25 13:11:19.526 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on licenses.graphpad.com:64140 (size: 19.7 KiB, free: 912.2 MiB)
24/08/25 13:11:19.527 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:19.530 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[85] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:19.531 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/08/25 13:11:19.536 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:26) as input to shuffle 1
24/08/25 13:11:19.536 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 20 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:19.537 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 19 (collect at utils.scala:26)
24/08/25 13:11:19.536 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 30) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes) taskResourceAssignments Map()
24/08/25 13:11:19.537 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:11:19.537 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:19.539 Executor task launch worker for task 0.0 in stage 18.0 (TID 30) INFO Executor: Running task 0.0 in stage 18.0 (TID 30)
24/08/25 13:11:19.540 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[87] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:19.548 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 10.6 KiB, free 912.1 MiB)
24/08/25 13:11:19.553 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 912.1 MiB)
24/08/25 13:11:19.559 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on licenses.graphpad.com:64140 (size: 5.6 KiB, free: 912.2 MiB)
24/08/25 13:11:19.560 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:19.567 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[87] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:19.567 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/08/25 13:11:19.570 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8197 bytes) taskResourceAssignments Map()
24/08/25 13:11:19.572 Executor task launch worker for task 0.0 in stage 19.0 (TID 31) INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
24/08/25 13:11:19.620 Executor task launch worker for task 0.0 in stage 18.0 (TID 30) INFO MemoryStore: Block rdd_80_0 stored as values in memory (estimated size 336.0 B, free 912.1 MiB)
24/08/25 13:11:19.626 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_80_0 in memory on licenses.graphpad.com:64140 (size: 336.0 B, free: 912.2 MiB)
24/08/25 13:11:19.677 Executor task launch worker for task 0.0 in stage 18.0 (TID 30) INFO CodeGenerator: Code generated in 48.5822 ms
24/08/25 13:11:19.695 Executor task launch worker for task 0.0 in stage 19.0 (TID 31) INFO CodeGenerator: Code generated in 59.2355 ms
24/08/25 13:11:19.757 Executor task launch worker for task 0.0 in stage 18.0 (TID 30) INFO CodeGenerator: Code generated in 61.2049 ms
24/08/25 13:11:19.893 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on licenses.graphpad.com:64140 in memory (size: 3.6 KiB, free: 912.2 MiB)
24/08/25 13:11:19.924 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:11:19.950 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:11:19.982 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on licenses.graphpad.com:64140 in memory (size: 3.6 KiB, free: 912.2 MiB)
24/08/25 13:11:20.006 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:11:20.033 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:11:20.054 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:11:20.168 Executor task launch worker for task 0.0 in stage 18.0 (TID 30) INFO Executor: Finished task 0.0 in stage 18.0 (TID 30). 1997 bytes result sent to driver
24/08/25 13:11:20.174 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 30) in 642 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:20.174 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/08/25 13:11:20.179 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 18 (collect at utils.scala:26) finished in 0.703 s
24/08/25 13:11:20.180 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/08/25 13:11:20.181 dag-scheduler-event-loop INFO DAGScheduler: running: Set(ShuffleMapStage 19)
24/08/25 13:11:20.182 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/08/25 13:11:20.184 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/08/25 13:11:20.184 Executor task launch worker for task 0.0 in stage 19.0 (TID 31) INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 1713 bytes result sent to driver
24/08/25 13:11:20.188 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 619 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:20.189 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/08/25 13:11:20.204 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 19 (collect at utils.scala:26) finished in 0.663 s
24/08/25 13:11:20.205 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/08/25 13:11:20.205 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/08/25 13:11:20.206 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/08/25 13:11:20.206 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/08/25 13:11:20.321 nioEventLoopGroup-2-2 INFO ShufflePartitionsUtil: For shuffle(0, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
24/08/25 13:11:20.470 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 47.5064 ms
24/08/25 13:11:20.504 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 26.1594 ms
24/08/25 13:11:20.594 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 32.3721 ms
24/08/25 13:11:20.666 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:11:20.671 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:11:20.672 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
24/08/25 13:11:20.672 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 21)
24/08/25 13:11:20.672 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:11:20.675 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[94] at collect at utils.scala:26), which has no missing parents
24/08/25 13:11:20.699 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 63.3 KiB, free 912.1 MiB)
24/08/25 13:11:20.707 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 912.1 MiB)
24/08/25 13:11:20.708 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on licenses.graphpad.com:64140 (size: 27.4 KiB, free: 912.2 MiB)
24/08/25 13:11:20.709 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1509
24/08/25 13:11:20.710 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[94] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:11:20.711 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/08/25 13:11:20.722 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 32) (licenses.graphpad.com, executor driver, partition 0, NODE_LOCAL, 4735 bytes) taskResourceAssignments Map()
24/08/25 13:11:20.724 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO Executor: Running task 0.0 in stage 22.0 (TID 32)
24/08/25 13:11:20.865 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO ShuffleBlockFetcherIterator: Getting 1 (395.0 B) non-empty blocks including 1 (395.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/08/25 13:11:20.873 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 49 ms
24/08/25 13:11:20.990 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO CodeGenerator: Code generated in 79.2558 ms
24/08/25 13:11:21.099 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO CodeGenerator: Code generated in 51.9452 ms
24/08/25 13:11:21.165 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO ShuffleBlockFetcherIterator: Getting 1 (886.0 B) non-empty blocks including 1 (886.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/08/25 13:11:21.166 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/08/25 13:11:21.239 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO CodeGenerator: Code generated in 61.5159 ms
24/08/25 13:11:21.293 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO CodeGenerator: Code generated in 42.7655 ms
24/08/25 13:11:21.494 Executor task launch worker for task 0.0 in stage 22.0 (TID 32) INFO Executor: Finished task 0.0 in stage 22.0 (TID 32). 4699 bytes result sent to driver
24/08/25 13:11:21.497 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 32) in 782 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:11:21.497 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/08/25 13:11:21.499 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0.807 s
24/08/25 13:11:21.500 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:11:21.500 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/08/25 13:11:21.500 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: collect at utils.scala:26, took 0.834144 s
24/08/25 13:12:07.829 nioEventLoopGroup-2-2 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:12:07.829 nioEventLoopGroup-2-2 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:12:07.832 nioEventLoopGroup-2-2 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:12:08.564 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at <unknown>:0
24/08/25 13:12:08.566 dag-scheduler-event-loop INFO DAGScheduler: Got job 22 (csv at <unknown>:0) with 1 output partitions
24/08/25 13:12:08.567 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (csv at <unknown>:0)
24/08/25 13:12:08.567 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:12:08.568 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:12:08.571 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[97] at csv at <unknown>:0), which has no missing parents
24/08/25 13:12:08.639 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 219.0 KiB, free 911.8 MiB)
24/08/25 13:12:08.645 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 78.0 KiB, free 911.8 MiB)
24/08/25 13:12:08.647 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on licenses.graphpad.com:64140 (size: 78.0 KiB, free: 912.1 MiB)
24/08/25 13:12:08.648 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1509
24/08/25 13:12:08.650 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[97] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/08/25 13:12:08.651 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/08/25 13:12:08.655 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 33) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:12:08.657 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO Executor: Running task 0.0 in stage 23.0 (TID 33)
24/08/25 13:12:08.769 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:12:08.775 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:12:08.775 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:12:08.776 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:12:09.545 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO FileOutputCommitter: Saved output of task 'attempt_202408251312084013919225766649476_0023_m_000000_33' to file:/E:/GitHub/R/R_notes_version_0/data/spark/cars.csv/_temporary/0/task_202408251312084013919225766649476_0023_m_000000
24/08/25 13:12:09.547 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO SparkHadoopMapRedUtil: attempt_202408251312084013919225766649476_0023_m_000000_33: Committed. Elapsed time: 14 ms.
24/08/25 13:12:09.568 Executor task launch worker for task 0.0 in stage 23.0 (TID 33) INFO Executor: Finished task 0.0 in stage 23.0 (TID 33). 2708 bytes result sent to driver
24/08/25 13:12:09.571 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 33) in 917 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:12:09.571 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/08/25 13:12:09.572 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (csv at <unknown>:0) finished in 0.999 s
24/08/25 13:12:09.573 dag-scheduler-event-loop INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:12:09.574 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/08/25 13:12:09.575 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 22 finished: csv at <unknown>:0, took 1.009908 s
24/08/25 13:12:09.578 nioEventLoopGroup-2-2 INFO FileFormatWriter: Start to commit write Job be511b63-cd05-4b5f-a8d0-8c3107403ed9.
24/08/25 13:12:09.591 nioEventLoopGroup-2-2 ERROR FileFormatWriter: Aborting job be511b63-cd05-4b5f-a8d0-8c3107403ed9.
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1218)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1423)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$26(FileFormatWriter.scala:277)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:642)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:277)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:851)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:161)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:141)
	at sparklyr.StreamHandler.read(stream.scala:62)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:60)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:41)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:17:03.947 nioEventLoopGroup-2-2 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:17:03.950 nioEventLoopGroup-2-2 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:17:03.955 nioEventLoopGroup-2-2 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:17:04.573 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at <unknown>:0
24/08/25 13:17:04.588 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (csv at <unknown>:0) with 1 output partitions
24/08/25 13:17:04.589 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (csv at <unknown>:0)
24/08/25 13:17:04.589 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:17:04.598 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:17:04.606 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[100] at csv at <unknown>:0), which has no missing parents
24/08/25 13:17:04.803 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 219.0 KiB, free 911.6 MiB)
24/08/25 13:17:04.859 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 78.0 KiB, free 911.5 MiB)
24/08/25 13:17:04.864 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on licenses.graphpad.com:64140 (size: 78.0 KiB, free: 912.1 MiB)
24/08/25 13:17:04.869 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1509
24/08/25 13:17:04.872 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[100] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/08/25 13:17:04.876 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/08/25 13:17:04.903 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 34) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:17:04.916 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO Executor: Running task 0.0 in stage 24.0 (TID 34)
24/08/25 13:17:05.069 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:17:05.108 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:17:05.108 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:17:05.109 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:17:05.626 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO FileOutputCommitter: Saved output of task 'attempt_202408251317045291791204907561068_0024_m_000000_34' to file:/E:/GitHub/R/R_notes_version_0/data/spark/cars.csv/_temporary/0/task_202408251317045291791204907561068_0024_m_000000
24/08/25 13:17:05.627 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO SparkHadoopMapRedUtil: attempt_202408251317045291791204907561068_0024_m_000000_34: Committed. Elapsed time: 8 ms.
24/08/25 13:17:05.631 Executor task launch worker for task 0.0 in stage 24.0 (TID 34) INFO Executor: Finished task 0.0 in stage 24.0 (TID 34). 2665 bytes result sent to driver
24/08/25 13:17:05.637 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 34) in 743 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:17:05.637 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/08/25 13:17:05.639 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (csv at <unknown>:0) finished in 1.022 s
24/08/25 13:17:05.640 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:17:05.640 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/08/25 13:17:05.640 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: csv at <unknown>:0, took 1.064675 s
24/08/25 13:17:05.642 nioEventLoopGroup-2-2 INFO FileFormatWriter: Start to commit write Job c2351e91-7f31-4e0d-9b0a-3e848775ea4d.
24/08/25 13:17:05.652 nioEventLoopGroup-2-2 ERROR FileFormatWriter: Aborting job c2351e91-7f31-4e0d-9b0a-3e848775ea4d.
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1218)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1423)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$26(FileFormatWriter.scala:277)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:642)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:277)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:851)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:161)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:141)
	at sparklyr.StreamHandler.read(stream.scala:62)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:60)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:41)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:19:05.588 nioEventLoopGroup-2-2 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:19:05.588 nioEventLoopGroup-2-2 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:19:05.589 nioEventLoopGroup-2-2 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:19:06.080 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at <unknown>:0
24/08/25 13:19:06.082 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (csv at <unknown>:0) with 1 output partitions
24/08/25 13:19:06.083 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 25 (csv at <unknown>:0)
24/08/25 13:19:06.083 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:19:06.085 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:19:06.088 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[103] at csv at <unknown>:0), which has no missing parents
24/08/25 13:19:06.200 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 219.0 KiB, free 911.3 MiB)
24/08/25 13:19:06.238 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 78.0 KiB, free 911.2 MiB)
24/08/25 13:19:06.240 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on licenses.graphpad.com:64140 (size: 78.0 KiB, free: 912.0 MiB)
24/08/25 13:19:06.241 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1509
24/08/25 13:19:06.242 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[103] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/08/25 13:19:06.243 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/08/25 13:19:06.246 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 35) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:19:06.253 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO Executor: Running task 0.0 in stage 25.0 (TID 35)
24/08/25 13:19:06.388 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:19:06.397 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:19:06.397 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:19:06.398 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:19:06.970 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO FileOutputCommitter: Saved output of task 'attempt_202408251319052594686745633237307_0025_m_000000_35' to file:/E:/GitHub/R/R_notes_version_0/data/spark/cars.csv/_temporary/0/task_202408251319052594686745633237307_0025_m_000000
24/08/25 13:19:06.971 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO SparkHadoopMapRedUtil: attempt_202408251319052594686745633237307_0025_m_000000_35: Committed. Elapsed time: 9 ms.
24/08/25 13:19:06.974 Executor task launch worker for task 0.0 in stage 25.0 (TID 35) INFO Executor: Finished task 0.0 in stage 25.0 (TID 35). 2665 bytes result sent to driver
24/08/25 13:19:06.979 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 35) in 734 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:19:06.982 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 25 (csv at <unknown>:0) finished in 0.891 s
24/08/25 13:19:06.981 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/08/25 13:19:06.983 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:19:06.983 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
24/08/25 13:19:06.984 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: csv at <unknown>:0, took 0.904187 s
24/08/25 13:19:06.985 nioEventLoopGroup-2-2 INFO FileFormatWriter: Start to commit write Job a0070839-7fc4-4f84-b3f9-777174359ed4.
24/08/25 13:19:06.991 nioEventLoopGroup-2-2 ERROR FileFormatWriter: Aborting job a0070839-7fc4-4f84-b3f9-777174359ed4.
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1218)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1423)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$26(FileFormatWriter.scala:277)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:642)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:277)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:851)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:161)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:141)
	at sparklyr.StreamHandler.read(stream.scala:62)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:60)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:41)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:20:41.390 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 60.0 KiB, free 911.1 MiB)
24/08/25 13:20:42.108 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 12.1 KiB, free 911.1 MiB)
24/08/25 13:20:42.125 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on licenses.graphpad.com:64140 (size: 12.1 KiB, free: 912.0 MiB)
24/08/25 13:20:42.128 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 24 from broadcast at workerhelper.scala:104
24/08/25 13:20:42.132 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 40.0 B, free 911.3 MiB)
24/08/25 13:20:42.137 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on licenses.graphpad.com:64140 in memory (size: 78.0 KiB, free: 912.1 MiB)
24/08/25 13:20:42.155 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 69.0 B, free 911.5 MiB)
24/08/25 13:20:42.155 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on licenses.graphpad.com:64140 in memory (size: 78.0 KiB, free: 912.1 MiB)
24/08/25 13:20:42.157 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on licenses.graphpad.com:64140 (size: 69.0 B, free: 912.1 MiB)
24/08/25 13:20:42.158 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 25 from broadcast at workerhelper.scala:105
24/08/25 13:20:42.161 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 592.0 B, free 911.7 MiB)
24/08/25 13:20:42.190 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 293.0 B, free 911.8 MiB)
24/08/25 13:20:42.191 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on licenses.graphpad.com:64140 in memory (size: 78.0 KiB, free: 912.2 MiB)
24/08/25 13:20:42.192 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on licenses.graphpad.com:64140 (size: 293.0 B, free: 912.2 MiB)
24/08/25 13:20:42.194 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 26 from broadcast at workerhelper.scala:106
24/08/25 13:20:42.195 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 1320.0 B, free 912.0 MiB)
24/08/25 13:20:42.206 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on licenses.graphpad.com:64140 in memory (size: 5.6 KiB, free: 912.2 MiB)
24/08/25 13:20:42.227 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 501.0 B, free 912.0 MiB)
24/08/25 13:20:42.235 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on licenses.graphpad.com:64140 (size: 501.0 B, free: 912.2 MiB)
24/08/25 13:20:42.237 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 27 from broadcast at workerhelper.scala:107
24/08/25 13:20:42.239 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 1928.0 B, free 912.0 MiB)
24/08/25 13:20:42.249 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on licenses.graphpad.com:64140 in memory (size: 27.4 KiB, free: 912.2 MiB)
24/08/25 13:20:42.263 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on licenses.graphpad.com:64140 in memory (size: 19.7 KiB, free: 912.3 MiB)
24/08/25 13:20:42.266 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 1033.0 B, free 912.1 MiB)
24/08/25 13:20:42.267 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on licenses.graphpad.com:64140 (size: 1033.0 B, free: 912.3 MiB)
24/08/25 13:20:42.269 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 28 from broadcast at workerhelper.scala:108
24/08/25 13:20:42.945 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 110.8508 ms
24/08/25 13:20:42.985 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 108 (collect at utils.scala:26) as input to shuffle 2
24/08/25 13:20:42.986 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 25 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:20:42.986 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 26 (collect at utils.scala:26)
24/08/25 13:20:42.987 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:20:42.988 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:20:42.990 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[108] at collect at utils.scala:26), which has no missing parents
24/08/25 13:20:43.029 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 22.5 KiB, free 912.1 MiB)
24/08/25 13:20:43.045 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 912.1 MiB)
24/08/25 13:20:43.047 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on licenses.graphpad.com:64140 (size: 8.7 KiB, free: 912.3 MiB)
24/08/25 13:20:43.048 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1509
24/08/25 13:20:43.051 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[108] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:20:43.052 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
24/08/25 13:20:43.061 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 36) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8197 bytes) taskResourceAssignments Map()
24/08/25 13:20:43.068 Executor task launch worker for task 0.0 in stage 26.0 (TID 36) INFO Executor: Running task 0.0 in stage 26.0 (TID 36)
24/08/25 13:20:43.086 Executor task launch worker for task 0.0 in stage 26.0 (TID 36) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:20:43.162 Executor task launch worker for task 0.0 in stage 26.0 (TID 36) INFO Executor: 1 block locks were not released by task 0.0 in stage 26.0 (TID 36)
[rdd_11_0]
24/08/25 13:20:43.164 Executor task launch worker for task 0.0 in stage 26.0 (TID 36) INFO Executor: Finished task 0.0 in stage 26.0 (TID 36). 1990 bytes result sent to driver
24/08/25 13:20:43.169 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 36) in 111 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:20:43.170 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
24/08/25 13:20:43.173 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:26) finished in 0.180 s
24/08/25 13:20:43.173 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/08/25 13:20:43.174 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/08/25 13:20:43.174 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/08/25 13:20:43.174 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/08/25 13:20:43.341 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 101.6429 ms
24/08/25 13:20:43.477 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:20:43.480 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:20:43.480 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:26)
24/08/25 13:20:43.480 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
24/08/25 13:20:43.481 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:20:43.490 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[113] at collect at utils.scala:26), which has no missing parents
24/08/25 13:20:43.516 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 41.2 KiB, free 912.1 MiB)
24/08/25 13:20:43.622 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 16.1 KiB, free 912.1 MiB)
24/08/25 13:20:43.632 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on licenses.graphpad.com:64140 (size: 16.1 KiB, free: 912.2 MiB)
24/08/25 13:20:43.634 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1509
24/08/25 13:20:43.635 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[113] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:20:43.635 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/08/25 13:20:43.657 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 37) (licenses.graphpad.com, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
24/08/25 13:20:43.659 Executor task launch worker for task 0.0 in stage 28.0 (TID 37) INFO Executor: Running task 0.0 in stage 28.0 (TID 37)
24/08/25 13:20:43.805 Executor task launch worker for task 0.0 in stage 28.0 (TID 37) INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/08/25 13:20:43.807 Executor task launch worker for task 0.0 in stage 28.0 (TID 37) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
24/08/25 13:21:03.307 Executor task launch worker for task 0.0 in stage 28.0 (TID 37) INFO Executor: Finished task 0.0 in stage 28.0 (TID 37). 2977 bytes result sent to driver
24/08/25 13:21:03.312 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 37) in 19667 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:21:03.313 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/08/25 13:21:03.317 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 28 (collect at utils.scala:26) finished in 19.822 s
24/08/25 13:21:03.318 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:21:03.318 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
24/08/25 13:21:03.319 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 19.840770 s
24/08/25 13:21:03.374 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 41.7152 ms
24/08/25 13:21:04.630 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 60.0 KiB, free 912.0 MiB)
24/08/25 13:21:04.645 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 12.1 KiB, free 912.0 MiB)
24/08/25 13:21:04.647 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on licenses.graphpad.com:64140 (size: 12.1 KiB, free: 912.2 MiB)
24/08/25 13:21:04.649 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 31 from broadcast at workerhelper.scala:104
24/08/25 13:21:04.651 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 40.0 B, free 912.0 MiB)
24/08/25 13:21:04.689 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 69.0 B, free 912.0 MiB)
24/08/25 13:21:04.691 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on licenses.graphpad.com:64140 (size: 69.0 B, free: 912.2 MiB)
24/08/25 13:21:04.692 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 32 from broadcast at workerhelper.scala:105
24/08/25 13:21:04.694 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 592.0 B, free 912.0 MiB)
24/08/25 13:21:04.742 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 293.0 B, free 912.0 MiB)
24/08/25 13:21:04.743 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on licenses.graphpad.com:64140 (size: 293.0 B, free: 912.2 MiB)
24/08/25 13:21:04.745 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 33 from broadcast at workerhelper.scala:106
24/08/25 13:21:04.748 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 1320.0 B, free 912.0 MiB)
24/08/25 13:21:04.800 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 501.0 B, free 912.0 MiB)
24/08/25 13:21:04.802 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on licenses.graphpad.com:64140 (size: 501.0 B, free: 912.2 MiB)
24/08/25 13:21:04.804 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 34 from broadcast at workerhelper.scala:107
24/08/25 13:21:04.805 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 1928.0 B, free 912.0 MiB)
24/08/25 13:21:04.877 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 1033.0 B, free 912.0 MiB)
24/08/25 13:21:04.879 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on licenses.graphpad.com:64140 (size: 1033.0 B, free: 912.2 MiB)
24/08/25 13:21:04.880 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 35 from broadcast at workerhelper.scala:108
24/08/25 13:21:06.215 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:21:06.220 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:21:06.220 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:26)
24/08/25 13:21:06.220 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:21:06.220 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:21:06.222 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[115] at collect at utils.scala:26), which has no missing parents
24/08/25 13:21:06.229 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.5 KiB, free 912.0 MiB)
24/08/25 13:21:06.336 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.0 MiB)
24/08/25 13:21:06.344 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on licenses.graphpad.com:64140 (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:21:06.345 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1509
24/08/25 13:21:06.346 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[115] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:21:06.346 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
24/08/25 13:21:06.349 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 38) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:21:06.352 Executor task launch worker for task 0.0 in stage 29.0 (TID 38) INFO Executor: Running task 0.0 in stage 29.0 (TID 38)
24/08/25 13:21:06.363 Executor task launch worker for task 0.0 in stage 29.0 (TID 38) INFO Executor: Finished task 0.0 in stage 29.0 (TID 38). 1319 bytes result sent to driver
24/08/25 13:21:06.366 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 38) in 18 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:21:06.368 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
24/08/25 13:21:06.370 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 29 (collect at utils.scala:26) finished in 0.146 s
24/08/25 13:21:06.370 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:21:06.370 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
24/08/25 13:21:06.371 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: collect at utils.scala:26, took 0.156734 s
24/08/25 13:21:08.873 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 38.1683 ms
24/08/25 13:21:09.081 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 115.5054 ms
24/08/25 13:21:09.180 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 128 (sql at <unknown>:0) as input to shuffle 3
24/08/25 13:21:09.181 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 28 (sql at <unknown>:0) with 1 output partitions
24/08/25 13:21:09.181 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 30 (sql at <unknown>:0)
24/08/25 13:21:09.181 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:21:09.185 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:21:09.188 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[128] at sql at <unknown>:0), which has no missing parents
24/08/25 13:21:09.205 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 54.3 KiB, free 911.9 MiB)
24/08/25 13:21:09.247 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 911.9 MiB)
24/08/25 13:21:09.248 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on licenses.graphpad.com:64140 (size: 15.9 KiB, free: 912.2 MiB)
24/08/25 13:21:09.249 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1509
24/08/25 13:21:09.250 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[128] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/08/25 13:21:09.251 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
24/08/25 13:21:09.256 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8197 bytes) taskResourceAssignments Map()
24/08/25 13:21:09.259 Executor task launch worker for task 0.0 in stage 30.0 (TID 39) INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
24/08/25 13:21:09.284 Executor task launch worker for task 0.0 in stage 30.0 (TID 39) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:21:39.225 Executor task launch worker for task 0.0 in stage 30.0 (TID 39) INFO MemoryStore: Block rdd_123_0 stored as values in memory (estimated size 4.2 KiB, free 911.9 MiB)
24/08/25 13:21:39.228 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_123_0 in memory on licenses.graphpad.com:64140 (size: 4.2 KiB, free: 912.2 MiB)
24/08/25 13:21:39.288 Executor task launch worker for task 0.0 in stage 30.0 (TID 39) INFO CodeGenerator: Code generated in 55.8567 ms
24/08/25 13:21:39.373 Executor task launch worker for task 0.0 in stage 30.0 (TID 39) INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 2329 bytes result sent to driver
24/08/25 13:21:39.379 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 30124 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:21:39.380 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
24/08/25 13:21:39.382 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 30 (sql at <unknown>:0) finished in 30.192 s
24/08/25 13:21:39.384 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/08/25 13:21:39.384 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/08/25 13:21:39.384 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/08/25 13:21:39.385 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/08/25 13:21:39.473 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 27.6689 ms
24/08/25 13:21:39.560 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: sql at <unknown>:0
24/08/25 13:21:39.566 dag-scheduler-event-loop INFO DAGScheduler: Got job 29 (sql at <unknown>:0) with 1 output partitions
24/08/25 13:21:39.566 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
24/08/25 13:21:39.566 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
24/08/25 13:21:39.567 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:21:39.569 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[131] at sql at <unknown>:0), which has no missing parents
24/08/25 13:21:39.576 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 11.1 KiB, free 911.9 MiB)
24/08/25 13:21:39.629 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 911.9 MiB)
24/08/25 13:21:39.630 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on licenses.graphpad.com:64140 (size: 5.5 KiB, free: 912.2 MiB)
24/08/25 13:21:39.630 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1509
24/08/25 13:21:39.633 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[131] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/08/25 13:21:39.633 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
24/08/25 13:21:39.637 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 40) (licenses.graphpad.com, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
24/08/25 13:21:39.639 Executor task launch worker for task 0.0 in stage 32.0 (TID 40) INFO Executor: Running task 0.0 in stage 32.0 (TID 40)
24/08/25 13:21:39.676 Executor task launch worker for task 0.0 in stage 32.0 (TID 40) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/08/25 13:21:39.678 Executor task launch worker for task 0.0 in stage 32.0 (TID 40) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
24/08/25 13:21:39.707 Executor task launch worker for task 0.0 in stage 32.0 (TID 40) INFO Executor: Finished task 0.0 in stage 32.0 (TID 40). 2613 bytes result sent to driver
24/08/25 13:21:39.712 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 40) in 75 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:21:39.713 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
24/08/25 13:21:39.714 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0.140 s
24/08/25 13:21:39.715 dag-scheduler-event-loop INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:21:39.715 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
24/08/25 13:21:39.717 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 29 finished: sql at <unknown>:0, took 0.155420 s
24/08/25 13:21:40.597 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:21:40.599 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:21:40.599 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:26)
24/08/25 13:21:40.599 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:21:40.600 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:21:40.606 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[135] at collect at utils.scala:26), which has no missing parents
24/08/25 13:21:40.616 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 50.1 KiB, free 911.8 MiB)
24/08/25 13:21:40.640 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 911.8 MiB)
24/08/25 13:21:40.643 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on licenses.graphpad.com:64140 (size: 14.1 KiB, free: 912.2 MiB)
24/08/25 13:21:40.644 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1509
24/08/25 13:21:40.645 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[135] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:21:40.645 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
24/08/25 13:21:40.648 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 41) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:21:40.652 Executor task launch worker for task 0.0 in stage 33.0 (TID 41) INFO Executor: Running task 0.0 in stage 33.0 (TID 41)
24/08/25 13:21:40.669 Executor task launch worker for task 0.0 in stage 33.0 (TID 41) INFO BlockManager: Found block rdd_123_0 locally
24/08/25 13:21:40.677 Executor task launch worker for task 0.0 in stage 33.0 (TID 41) INFO Executor: Finished task 0.0 in stage 33.0 (TID 41). 2694 bytes result sent to driver
24/08/25 13:21:40.679 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 41) in 31 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:21:40.680 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
24/08/25 13:21:40.681 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (collect at utils.scala:26) finished in 0.072 s
24/08/25 13:21:40.682 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:21:40.683 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
24/08/25 13:21:40.683 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: collect at utils.scala:26, took 0.086026 s
24/08/25 13:30:20.185 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:30:20.210 dag-scheduler-event-loop INFO DAGScheduler: Got job 31 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:30:20.210 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:26)
24/08/25 13:30:20.211 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:30:20.218 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:30:20.226 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[139] at collect at utils.scala:26), which has no missing parents
24/08/25 13:30:20.290 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 16.0 KiB, free 911.8 MiB)
24/08/25 13:30:20.346 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 911.8 MiB)
24/08/25 13:30:20.352 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on licenses.graphpad.com:64140 (size: 6.9 KiB, free: 912.2 MiB)
24/08/25 13:30:20.355 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1509
24/08/25 13:30:20.359 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[139] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:30:20.360 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/08/25 13:30:20.390 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 42) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:30:20.405 Executor task launch worker for task 0.0 in stage 34.0 (TID 42) INFO Executor: Running task 0.0 in stage 34.0 (TID 42)
24/08/25 13:30:20.478 Executor task launch worker for task 0.0 in stage 34.0 (TID 42) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:30:20.513 Executor task launch worker for task 0.0 in stage 34.0 (TID 42) INFO Executor: 1 block locks were not released by task 0.0 in stage 34.0 (TID 42)
[rdd_11_0]
24/08/25 13:30:20.517 Executor task launch worker for task 0.0 in stage 34.0 (TID 42) INFO Executor: Finished task 0.0 in stage 34.0 (TID 42). 1825 bytes result sent to driver
24/08/25 13:30:20.525 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 42) in 143 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:30:20.526 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/08/25 13:30:20.528 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 34 (collect at utils.scala:26) finished in 0.288 s
24/08/25 13:30:20.530 dag-scheduler-event-loop INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:30:20.530 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
24/08/25 13:30:20.531 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 31 finished: collect at utils.scala:26, took 0.336664 s
24/08/25 13:36:34.576 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on licenses.graphpad.com:64140 in memory (size: 5.5 KiB, free: 912.2 MiB)
24/08/25 13:36:34.611 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on licenses.graphpad.com:64140 in memory (size: 3.7 KiB, free: 912.2 MiB)
24/08/25 13:36:34.637 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on licenses.graphpad.com:64140 in memory (size: 15.9 KiB, free: 912.2 MiB)
24/08/25 13:36:34.660 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on licenses.graphpad.com:64140 in memory (size: 6.9 KiB, free: 912.2 MiB)
24/08/25 13:36:34.677 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on licenses.graphpad.com:64140 in memory (size: 14.1 KiB, free: 912.2 MiB)
24/08/25 13:36:34.694 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on licenses.graphpad.com:64140 in memory (size: 8.7 KiB, free: 912.2 MiB)
24/08/25 13:36:34.708 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on licenses.graphpad.com:64140 in memory (size: 16.1 KiB, free: 912.2 MiB)
24/08/25 13:38:44.343 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on licenses.graphpad.com:64140 in memory (size: 22.8 KiB, free: 912.3 MiB)
24/08/25 13:39:35.639 nioEventLoopGroup-2-2 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:39:35.640 nioEventLoopGroup-2-2 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:39:35.641 nioEventLoopGroup-2-2 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:39:36.171 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at <unknown>:0
24/08/25 13:39:36.179 dag-scheduler-event-loop INFO DAGScheduler: Got job 32 (csv at <unknown>:0) with 1 output partitions
24/08/25 13:39:36.180 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (csv at <unknown>:0)
24/08/25 13:39:36.180 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:39:36.181 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:39:36.184 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at csv at <unknown>:0), which has no missing parents
24/08/25 13:39:36.291 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 219.0 KiB, free 911.9 MiB)
24/08/25 13:39:36.324 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 78.0 KiB, free 911.8 MiB)
24/08/25 13:39:36.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on licenses.graphpad.com:64140 (size: 78.0 KiB, free: 912.2 MiB)
24/08/25 13:39:36.327 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1509
24/08/25 13:39:36.328 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/08/25 13:39:36.329 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
24/08/25 13:39:36.341 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 43) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:39:36.348 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO Executor: Running task 0.0 in stage 35.0 (TID 43)
24/08/25 13:39:36.448 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO BlockManager: Found block rdd_11_0 locally
24/08/25 13:39:36.465 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO FileOutputCommitter: File Output Committer Algorithm version is 1
24/08/25 13:39:36.465 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
24/08/25 13:39:36.466 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
24/08/25 13:39:37.172 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO FileOutputCommitter: Saved output of task 'attempt_20240825133936114650008590482390_0035_m_000000_43' to file:/E:/GitHub/R/R_notes_version_0/data/spark/cars.csv/_temporary/0/task_20240825133936114650008590482390_0035_m_000000
24/08/25 13:39:37.173 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO SparkHadoopMapRedUtil: attempt_20240825133936114650008590482390_0035_m_000000_43: Committed. Elapsed time: 12 ms.
24/08/25 13:39:37.176 Executor task launch worker for task 0.0 in stage 35.0 (TID 43) INFO Executor: Finished task 0.0 in stage 35.0 (TID 43). 2665 bytes result sent to driver
24/08/25 13:39:37.180 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 43) in 842 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:39:37.180 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
24/08/25 13:39:37.181 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (csv at <unknown>:0) finished in 0.991 s
24/08/25 13:39:37.182 dag-scheduler-event-loop INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:39:37.182 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
24/08/25 13:39:37.183 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 32 finished: csv at <unknown>:0, took 1.010969 s
24/08/25 13:39:37.184 nioEventLoopGroup-2-2 INFO FileFormatWriter: Start to commit write Job fbd3092b-497c-4b48-88b6-9f29b0dd02d9.
24/08/25 13:39:37.193 nioEventLoopGroup-2-2 ERROR FileFormatWriter: Aborting job fbd3092b-497c-4b48-88b6-9f29b0dd02d9.
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1218)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1423)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$26(FileFormatWriter.scala:277)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:642)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:277)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:851)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:161)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:141)
	at sparklyr.StreamHandler.read(stream.scala:62)
	at sparklyr.BackendHandler.$anonfun$channelRead0$1(handler.scala:60)
	at scala.util.control.Breaks.breakable(Breaks.scala:42)
	at sparklyr.BackendHandler.channelRead0(handler.scala:41)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:40:53.524 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/08/25 13:40:53.669 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://licenses.graphpad.com:4040
24/08/25 13:40:53.738 dispatcher-event-loop-4 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/08/25 13:40:54.218 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/08/25 13:40:54.220 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/08/25 13:40:54.242 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/08/25 13:40:54.261 dispatcher-event-loop-5 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/08/25 13:40:54.293 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387\userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7
java.io.IOException: Failed to delete: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387\userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2150)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2150)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:670)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:40:54.299 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/08/25 13:40:54.301 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/08/25 13:40:54.303 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387\userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7
24/08/25 13:40:54.310 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387\userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7
java.io.IOException: Failed to delete: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387\userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:40:54.311 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\DELL\AppData\Local\Temp\spark-2f0dc23f-85be-4889-8f22-df82bc6ec35a
24/08/25 13:40:54.319 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387
24/08/25 13:40:54.328 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387
java.io.IOException: Failed to delete: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-0f0d4f7f-1897-4deb-8740-de4558b43387\userFiles-35c44c06-e29a-41ba-9e7c-0bbada251af7\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:44:23.365 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/E:/spark/spark-3.3.4-bin-hadoop3/conf/hive-site.xml
24/08/25 13:44:24.106 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.4
24/08/25 13:44:24.186 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/08/25 13:44:24.429 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/08/25 13:44:24.550 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/08/25 13:44:24.553 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/08/25 13:44:24.554 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/08/25 13:44:24.557 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/08/25 13:44:24.672 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/08/25 13:44:24.722 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/08/25 13:44:24.725 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/08/25 13:44:25.102 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: DELL
24/08/25 13:44:25.104 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: DELL
24/08/25 13:44:25.106 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/08/25 13:44:25.108 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/08/25 13:44:25.110 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(DELL); groups with view permissions: Set(); users  with modify permissions: Set(DELL); groups with modify permissions: Set()
24/08/25 13:44:25.554 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 53247.
24/08/25 13:44:25.668 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/08/25 13:44:25.834 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/08/25 13:44:25.960 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/08/25 13:44:25.963 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/08/25 13:44:25.976 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/08/25 13:44:26.084 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\blockmgr-ffdbe61a-a1f1-428c-8377-674fce92dff0
24/08/25 13:44:26.163 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/08/25 13:44:26.237 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/08/25 13:44:26.248 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [E:/spark/spark-3.3.4-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/08/25 13:44:27.269 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/08/25 13:44:27.435 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/D:/R-4.4.1/library/sparklyr/java/sparklyr-3.0-2.12.jar at spark://licenses.graphpad.com:53247/jars/sparklyr-3.0-2.12.jar with timestamp 1724564664083
24/08/25 13:44:27.754 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host licenses.graphpad.com
24/08/25 13:44:27.790 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/08/25 13:44:27.843 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://licenses.graphpad.com:53247/jars/sparklyr-3.0-2.12.jar with timestamp 1724564664083
24/08/25 13:44:28.007 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to licenses.graphpad.com/127.0.0.1:53247 after 70 ms (0 ms spent in bootstraps)
24/08/25 13:44:28.024 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://licenses.graphpad.com:53247/jars/sparklyr-3.0-2.12.jar to E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38\userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb\fetchFileTemp1079249116403756975.tmp
24/08/25 13:44:28.304 nioEventLoopGroup-2-2 INFO Executor: Adding file:/E:/spark/spark-3.3.4-bin-hadoop3/tmp/local/spark-42b426e5-1ea8-480c-99de-9172d4d62d38/userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb/sparklyr-3.0-2.12.jar to class loader
24/08/25 13:44:28.356 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53299.
24/08/25 13:44:28.357 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on licenses.graphpad.com:53299
24/08/25 13:44:28.361 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/08/25 13:44:28.395 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, licenses.graphpad.com, 53299, None)
24/08/25 13:44:28.411 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager licenses.graphpad.com:53299 with 912.3 MiB RAM, BlockManagerId(driver, licenses.graphpad.com, 53299, None)
24/08/25 13:44:28.423 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, licenses.graphpad.com, 53299, None)
24/08/25 13:44:28.426 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, licenses.graphpad.com, 53299, None)
24/08/25 13:44:29.509 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('E:/spark/spark-3.3.4-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/08/25 13:44:29.544 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/E:/spark/spark-3.3.4-bin-hadoop3/tmp/hive'.
24/08/25 13:44:42.337 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/08/25 13:44:42.862 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/E:/spark/spark-3.3.4-bin-hadoop3/conf/hive-site.xml
24/08/25 13:44:43.717 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/E:/spark/spark-3.3.4-bin-hadoop3/tmp/hive
24/08/25 13:44:44.790 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/08/25 13:44:44.792 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/08/25 13:44:44.793 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/08/25 13:44:44.965 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/08/25 13:44:45.515 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/08/25 13:44:45.518 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/08/25 13:44:49.305 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/08/25 13:44:55.592 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/08/25 13:44:55.599 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/08/25 13:44:55.846 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/08/25 13:44:55.847 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.43.97
24/08/25 13:44:55.939 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/08/25 13:44:56.483 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/08/25 13:44:56.489 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/08/25 13:44:56.616 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/08/25 13:44:57.015 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:44:57.024 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:44:57.098 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/08/25 13:44:57.099 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/08/25 13:44:57.104 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/08/25 13:44:57.107 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:44:57.108 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:44:57.115 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:44:57.116 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:44:57.122 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:44:57.124 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:45:05.856 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:45:05.857 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:45:05.863 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:45:05.864 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:45:05.870 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:45:05.871 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:45:08.101 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 637.7882 ms
24/08/25 13:45:08.560 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:45:08.583 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0.018234 s
24/08/25 13:45:10.378 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 32.1411 ms
24/08/25 13:45:10.440 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:45:10.490 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:45:10.492 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/08/25 13:45:10.492 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:45:10.497 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:45:10.507 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
24/08/25 13:45:10.744 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
24/08/25 13:45:11.700 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
24/08/25 13:45:11.715 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on licenses.graphpad.com:53299 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:45:11.731 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1509
24/08/25 13:45:11.789 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:45:11.793 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/08/25 13:45:12.016 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:45:12.077 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/08/25 13:45:13.044 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
24/08/25 13:45:13.069 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1108 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:45:13.077 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/08/25 13:45:13.097 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 2.540 s
24/08/25 13:45:13.110 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:45:13.112 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/08/25 13:45:13.116 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 2.675503 s
24/08/25 13:45:13.244 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 52.3052 ms
24/08/25 13:45:14.049 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:45:14.052 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:45:14.053 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/08/25 13:45:14.053 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:45:14.054 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:45:14.058 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
24/08/25 13:45:14.066 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.5 KiB, free 912.3 MiB)
24/08/25 13:45:14.073 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
24/08/25 13:45:14.075 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on licenses.graphpad.com:53299 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:45:14.076 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1509
24/08/25 13:45:14.078 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:45:14.079 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/08/25 13:45:14.085 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
24/08/25 13:45:14.087 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/08/25 13:45:14.106 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1362 bytes result sent to driver
24/08/25 13:45:14.110 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 26 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:45:14.111 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/08/25 13:45:14.112 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0.051 s
24/08/25 13:45:14.113 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:45:14.114 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/08/25 13:45:14.115 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0.064351 s
24/08/25 13:45:17.270 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:45:17.270 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:45:17.276 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:45:17.277 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:45:17.284 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:45:17.285 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:45:17.521 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 127.3438 ms
24/08/25 13:45:17.637 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.6813 ms
24/08/25 13:45:17.687 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 23.9183 ms
24/08/25 13:45:18.423 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 45.0565 ms
24/08/25 13:45:18.519 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:45:18.522 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:45:18.523 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/08/25 13:45:18.523 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:45:18.538 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:45:18.541 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26), which has no missing parents
24/08/25 13:45:18.606 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 16.0 KiB, free 912.3 MiB)
24/08/25 13:45:18.617 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 912.3 MiB)
24/08/25 13:45:18.622 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on licenses.graphpad.com:53299 (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:45:18.624 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1509
24/08/25 13:45:18.626 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:45:18.626 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/08/25 13:45:18.639 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 8208 bytes) taskResourceAssignments Map()
24/08/25 13:45:18.643 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/08/25 13:45:18.987 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 4.2 KiB, free 912.3 MiB)
24/08/25 13:45:18.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_11_0 in memory on licenses.graphpad.com:53299 (size: 4.2 KiB, free: 912.3 MiB)
24/08/25 13:45:19.137 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 83.8073 ms
24/08/25 13:45:19.343 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 176.03 ms
24/08/25 13:45:19.371 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2784 bytes result sent to driver
24/08/25 13:45:19.391 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 760 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:45:19.391 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/08/25 13:45:19.393 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0.849 s
24/08/25 13:45:19.394 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:45:19.395 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/08/25 13:45:19.395 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0.875566 s
24/08/25 13:45:19.436 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 30.3445 ms
24/08/25 13:45:50.827 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:45:50.828 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:45:50.838 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:45:50.838 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:45:50.844 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:45:50.845 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:45:51.060 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:45:51.062 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:45:51.063 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/08/25 13:45:51.064 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:45:51.065 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:45:51.068 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[18] at collect at utils.scala:26), which has no missing parents
24/08/25 13:45:51.076 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KiB, free 912.2 MiB)
24/08/25 13:45:51.083 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:45:51.086 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on licenses.graphpad.com:53299 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:45:51.087 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1509
24/08/25 13:45:51.089 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:45:51.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/08/25 13:45:51.094 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4649 bytes) taskResourceAssignments Map()
24/08/25 13:45:51.099 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/08/25 13:45:51.131 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1334 bytes result sent to driver
24/08/25 13:45:51.138 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 45 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:45:51.139 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/08/25 13:45:51.141 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0.069 s
24/08/25 13:45:51.141 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:45:51.142 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/08/25 13:45:51.143 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0.081942 s
24/08/25 13:45:51.174 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.9625 ms
24/08/25 13:46:05.199 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:46:05.200 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:46:05.227 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/08/25 13:46:05.228 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_database: default	
24/08/25 13:46:05.287 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/08/25 13:46:05.287 nioEventLoopGroup-2-2 INFO audit: ugi=DELL	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/08/25 13:46:05.657 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/08/25 13:46:05.660 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/08/25 13:46:05.661 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/08/25 13:46:05.661 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/08/25 13:46:05.666 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/08/25 13:46:05.671 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:26), which has no missing parents
24/08/25 13:46:05.677 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.1 KiB, free 912.2 MiB)
24/08/25 13:46:05.688 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
24/08/25 13:46:05.692 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on licenses.graphpad.com:53299 (size: 3.7 KiB, free: 912.3 MiB)
24/08/25 13:46:05.693 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1509
24/08/25 13:46:05.695 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/08/25 13:46:05.696 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/08/25 13:46:05.700 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (licenses.graphpad.com, executor driver, partition 0, PROCESS_LOCAL, 4649 bytes) taskResourceAssignments Map()
24/08/25 13:46:05.704 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/08/25 13:46:05.719 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1377 bytes result sent to driver
24/08/25 13:46:05.721 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 22 ms on licenses.graphpad.com (executor driver) (1/1)
24/08/25 13:46:05.722 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/08/25 13:46:05.724 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0.050 s
24/08/25 13:46:05.725 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/08/25 13:46:05.725 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/08/25 13:46:05.728 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0.069463 s
24/08/25 13:51:15.273 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/08/25 13:51:15.381 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on licenses.graphpad.com:53299 in memory (size: 6.9 KiB, free: 912.3 MiB)
24/08/25 13:51:15.390 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://licenses.graphpad.com:4040
24/08/25 13:51:15.476 dispatcher-event-loop-7 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/08/25 13:51:15.580 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/08/25 13:51:15.582 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/08/25 13:51:15.597 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/08/25 13:51:15.618 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/08/25 13:51:15.651 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38\userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb
java.io.IOException: Failed to delete: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38\userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2150)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2150)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:670)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:51:15.664 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/08/25 13:51:15.667 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/08/25 13:51:15.671 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38\userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb
24/08/25 13:51:15.677 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38\userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb
java.io.IOException: Failed to delete: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38\userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:51:15.679 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38
24/08/25 13:51:15.687 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38
java.io.IOException: Failed to delete: E:\spark\spark-3.3.4-bin-hadoop3\tmp\local\spark-42b426e5-1ea8-480c-99de-9172d4d62d38\userFiles-09b79d36-5c15-47ad-9367-4d970f56c3cb\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
24/08/25 13:51:15.689 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\DELL\AppData\Local\Temp\spark-6a057a66-2955-4362-bb55-b7e6518be26a
